{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a57f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import argparse \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53921f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data, path): \n",
    "\t''' Encode objects values into numerical values '''\n",
    "\t\n",
    "\tfor col in data.columns : \n",
    "\t\tif data[col].dtype == 'object' : \n",
    "\n",
    "\t\t\tencoder = LabelEncoder()\n",
    "\t\t\tencoder.fit(data[col])\n",
    "\t\t\tdata[col] = encoder.transform(data[col]) \n",
    "\n",
    "\t\t\t# Save encoder\n",
    "\t\t\tencoder_file = path + '/' + col +'_encoder.sav'\n",
    "\t\t\tpickle.dump(encoder, open(encoder_file, 'wb'))\n",
    "\treturn data \n",
    "\n",
    "\n",
    "\n",
    "def scale(data): \n",
    "\t''' Scaling \n",
    "\tReturn scaled dataframe''' \n",
    "\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(data)\n",
    "\tdata = scaler.transform(data)\n",
    "\t# Save the scaler \n",
    "\tscalerfile = 'scaler.sav'\n",
    "\tpickle.dump(scaler, open(scalerfile, 'wb'))\n",
    "\treturn data\n",
    "\n",
    "\n",
    "\n",
    "def principal_comp_analysis(data, nb_comp, label_column): \n",
    "\t''' Principal components analysis transformation \n",
    "\tReturn transformed dataframe with nb_comp features'''\n",
    "\n",
    "\tfeatures_col = []\n",
    "\tfor col in data.columns: \n",
    "\t\tif col != label_column:\n",
    "\t\t\tfeatures_col.append(col)\n",
    "\n",
    "\tfeatures = data.drop([label_column], axis = 1)\n",
    "\tlabel_data = data[[label_column]]\n",
    "\n",
    "\tpca = PCA(n_components = nb_comp)\n",
    "\tpca.fit(features)\n",
    "\tdata_pc = pca.transform(features)\n",
    "\n",
    "\tcolumns = []\n",
    "\tfor i in range(nb_comp): \n",
    "\t\tcolumns.append('pc{}'.format(i+1))\n",
    "\n",
    "\tdf = pd.DataFrame(data = data_pc, columns = columns)\n",
    "\tdf = pd.concat([df, label_data], axis =1)\n",
    "\n",
    "\treturn df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954a9d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n",
      "Id                                                                           \n",
      "1              5.1           3.5            1.4           0.2     Iris-setosa\n",
      "2              4.9           3.0            1.4           0.2     Iris-setosa\n",
      "3              4.7           3.2            1.3           0.2     Iris-setosa\n",
      "4              4.6           3.1            1.5           0.2     Iris-setosa\n",
      "5              5.0           3.6            1.4           0.2     Iris-setosa\n",
      "..             ...           ...            ...           ...             ...\n",
      "146            6.7           3.0            5.2           2.3  Iris-virginica\n",
      "147            6.3           2.5            5.0           1.9  Iris-virginica\n",
      "148            6.5           3.0            5.2           2.0  Iris-virginica\n",
      "149            6.2           3.4            5.4           2.3  Iris-virginica\n",
      "150            5.9           3.0            5.1           1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "          pc1       pc2       pc3         Species\n",
      "0   -2.684207  0.326607 -0.021512             NaN\n",
      "1   -2.715391 -0.169557 -0.203521     Iris-setosa\n",
      "2   -2.889820 -0.137346  0.024709     Iris-setosa\n",
      "3   -2.746437 -0.311124  0.037672     Iris-setosa\n",
      "4   -2.728593  0.333925  0.096230     Iris-setosa\n",
      "..        ...       ...       ...             ...\n",
      "146  1.525664 -0.375021 -0.120636  Iris-virginica\n",
      "147  1.764046  0.078519  0.130784  Iris-virginica\n",
      "148  1.901629  0.115877  0.722874  Iris-virginica\n",
      "149  1.389666 -0.282887  0.362318  Iris-virginica\n",
      "150       NaN       NaN       NaN  Iris-virginica\n",
      "\n",
      "[151 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def load_data(path): \n",
    "    data = pd.read_csv(path, index_col = 0)\n",
    "    return data\n",
    "\n",
    "data = load_data(\"Iris.csv\")\n",
    "\n",
    "print (data)\n",
    "\n",
    "# print (encode_data(data,r\"C:\\Users\\gurve\\SI CP\\Data Preprocessing\\Data Transformation\"))\n",
    "\n",
    "# print (scale(data))\n",
    "\n",
    "print (principal_comp_analysis(data,3,\"Species\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98813f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc3333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
